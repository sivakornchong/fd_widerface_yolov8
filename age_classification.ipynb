{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e336bb8-f6d5-4b4d-9d32-e4ff21fe1b42",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Here, we will use RESNET34 architecture to train a classification model to identify the age range of images.\n",
    "\n",
    "Age range definition based on Health Promotion Board of Singapore\n",
    "- (A0) Young Children: 0-6 years \n",
    "- (A1) Children and Youth: 7-17 years \n",
    "- (A2) Youth Adults: 18-25 years\n",
    "- (A3) Adults: 26-49 years\n",
    "- (A4) Older adults: 50 years\n",
    "\n",
    "The training data used is from UTKFace. We will use In-the-wild dataset since it contains most data, and we have a face crop engine ready.\n",
    "Link: https://susanqq.github.io/UTKFace/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db91f2-ba92-404d-ae64-1bcc2245fd8f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92d1452e-e3ac-4588-aaf2-c5aa42546458",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/fd_widerface_yolov8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b139b6-6fa1-41c8-bbeb-218f394e93a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://oak_datastorage/utkface_dataset.zip\n",
      "gs://oak_datastorage/yolov8-face-20epoch.pt\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://oak_datastorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11629f15-3e84-47c3-8156-c0d2bb4bada0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://oak_datastorage/utkface_dataset.zip...\n",
      "- [1 files][  1.3 GiB/  1.3 GiB]   60.2 MiB/s                                   \n",
      "Operation completed over 1 objects/1.3 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://oak_datastorage/utkface_dataset.zip datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "574949c6-dec3-45f6-848f-ca5394a7c0ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Commented out since the action has been done and we would not want to overwhelm the jupyter lab with lengthy feedback print\n",
    "# !unzip datasets/utkface_dataset.zip -d datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4984e46b-1c85-44d7-820d-2c2d4ecde845",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images available: 24109\n",
      "Example directory: 58_0_0_20170120222516888.jpg\n"
     ]
    }
   ],
   "source": [
    "imglist = os.listdir(\"datasets/utkface_dataset\")\n",
    "print(\"Total number of images available:\", len(imglist))\n",
    "print(\"Example directory:\", imglist[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73dddc6-6341-4edd-a59c-fce7cdcf022e",
   "metadata": {},
   "source": [
    "The format of each data image is \\<age>_\\<gender>_\\<race>_\\<datetime>.jpg.\n",
    "\n",
    "Since we are trying to develop an age classification model, let us leave out all the other information and extract out only the age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c36023-b42e-41e7-b073-80bdefea3e4b",
   "metadata": {},
   "source": [
    "## Face Extraction\n",
    "\n",
    "Let us extract out faces from each frame for us to do age classification. By extracting out faces, the classifier can only look at facial information. The rationale for the focus on the face is to remove model biases that could originate from other potentially misleading information, such as clothing. \n",
    "\n",
    "We will extract the faces into a seperate folder, after which we would reorganize the data randomly into train, test and validation folder structure.\n",
    "\n",
    "We will drop those images where duplicate faces are detected (<5% of the whole dataset) to avoid misleading the model, as we are not 100% sure the label is for which face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "645714a3-4900-4ac5-81dd-25edd72681ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since we have 5 age ranges, this means we have 5 labels. We will incorperate this into the cropped file names\n",
    "def labelling(cropstr):\n",
    "    age = int(cropstr.split(\"_\")[0])\n",
    "    if age<=6:\n",
    "        agestr = \"A0\"\n",
    "    elif age<=17:\n",
    "        agestr = \"A1\"\n",
    "    elif age<=25:\n",
    "        agestr = \"A2\"\n",
    "    elif age<=49:\n",
    "        agestr = \"A3\"\n",
    "    else:\n",
    "        agestr = \"A4\"\n",
    "    return agestr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2d52c281-b025-43bd-84f0-208b2908e5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "\n",
    "save_directory = \"datasets/cropped_utkface/\"\n",
    "classNames = [\"face\"]\n",
    "\n",
    "def cropimgs(results, save_directory, expand_ratio = 0.2, CI = 0.7):\n",
    "    # results: list of results for all the images after running the model\n",
    "    # save_directory: location of output directory\n",
    "    # expand_ratio: expand the size of x1,x2 by expand_ratio percent. \n",
    "    # CI: confidence interval of prediction. Only crop the image if the confidence is higher than this threshold\n",
    "    \n",
    "    count = 0\n",
    "    dup_count = 0\n",
    "    \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        imgpath = r.path\n",
    "        img = cv2.imread(imgpath)\n",
    "        \n",
    "        cropstr = imgpath.split(\"/\")[-1].split(\".jpg\")[0]\n",
    "        agestr = labelling(cropstr)\n",
    "        \n",
    "        img_index = 0\n",
    "        \n",
    "        # In this module, we remove duplicate\n",
    "        if len(boxes)>1:\n",
    "            # print(\"More than one face detected!\")\n",
    "            dup_count += 1\n",
    "            continue\n",
    "\n",
    "        for box in boxes:\n",
    "            # bounding box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "            \n",
    "            # Calculate expanded coordinates\n",
    "            x1 = max(0, int(x1 - expand_ratio * (x2 - x1)))\n",
    "            y1 = max(0, int(y1 - expand_ratio * (y2 - y1)))\n",
    "            x2 = min(img.shape[1], int(x2 + expand_ratio * (x2 - x1)))\n",
    "            y2 = min(img.shape[0], int(y2 + expand_ratio * (y2 - y1)))\n",
    "\n",
    "            # put box in cam\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # confidence\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            # print(\"Confidence --->\",confidence)\n",
    "\n",
    "            # # class name\n",
    "            cls = int(box.cls[0])\n",
    "            # print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "            if classNames[cls] == \"face\" and confidence > CI:\n",
    "                # Crop the person from the image\n",
    "                cropped_person = img[y1:y2, x1:x2]\n",
    "\n",
    "                # Save the cropped person image\n",
    "                filename = f\"{save_directory}{cropstr}_{agestr}.jpg\"\n",
    "                cv2.imwrite(filename, cropped_person)\n",
    "                # img_index += 1\n",
    "                \n",
    "#                 if img_index > 1:\n",
    "#                     print(\"Possible duplicate faces at\", filename)\n",
    "                \n",
    "        count += 1\n",
    "        \n",
    "        if count%1000 == 0:\n",
    "            print(\"Success count:\", count)\n",
    "            print(\"Duplicate count:\", dup_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c2efc1d4-4097-4e6f-a0ac-4a9764bb352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'datasets/cropped_utkface/' created.\n"
     ]
    }
   ],
   "source": [
    "# Create directory first if it does not exist\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "    print(f\"Directory '{save_directory}' created.\")\n",
    "else:\n",
    "    print(f\"Directory '{save_directory}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "894b5a8d-816c-4248-be8d-0927f76b1dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 225 layers, 3011043 parameters, 0 gradients, 8.2 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(225, 3011043, 0, 8.1941504)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the best available face detection model\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('model/best.pt')\n",
    "img_dir = \"/home/jupyter/fd_widerface_yolov8/datasets/utkface_dataset/\"\n",
    "model.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72479ad0-2d2d-4a56-b8d4-c24bedb658a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done creating generator\n"
     ]
    }
   ],
   "source": [
    "# We will use generator for prediction to prevent overwhelming the CPU:\n",
    "results = model(img_dir, stream=True, verbose=False);\n",
    "print(\"Done creating generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66d39aef-9789-43a9-81f6-d90256d9ab9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 1000\n",
      "Duplicate count: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "Corrupt JPEG data: bad Huffman code\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 2000\n",
      "Duplicate count: 71\n",
      "Success count: 3000\n",
      "Duplicate count: 124\n",
      "Success count: 4000\n",
      "Duplicate count: 163\n",
      "Success count: 5000\n",
      "Duplicate count: 219\n",
      "Success count: 6000\n",
      "Duplicate count: 298\n",
      "Success count: 7000\n",
      "Duplicate count: 342\n",
      "Success count: 8000\n",
      "Duplicate count: 376\n",
      "Success count: 9000\n",
      "Duplicate count: 408\n",
      "Success count: 10000\n",
      "Duplicate count: 450\n",
      "Success count: 11000\n",
      "Duplicate count: 486\n",
      "Success count: 12000\n",
      "Duplicate count: 534\n",
      "Success count: 13000\n",
      "Duplicate count: 573\n",
      "Success count: 14000\n",
      "Duplicate count: 605\n",
      "Success count: 15000\n",
      "Duplicate count: 644\n",
      "Success count: 16000\n",
      "Duplicate count: 677\n",
      "Success count: 17000\n",
      "Duplicate count: 714\n",
      "Success count: 18000\n",
      "Duplicate count: 749\n",
      "Success count: 19000\n",
      "Duplicate count: 787\n",
      "Success count: 20000\n",
      "Duplicate count: 837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 21000\n",
      "Duplicate count: 880\n",
      "Success count: 22000\n",
      "Duplicate count: 928\n",
      "Success count: 23000\n",
      "Duplicate count: 973\n"
     ]
    }
   ],
   "source": [
    "# Process results generator\n",
    "cropimgs(results, save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835a6b0a-2f57-46ae-b5a8-be28398759f4",
   "metadata": {},
   "source": [
    "### Generation of dataset\n",
    "\n",
    "Here, we will generate folders for datasets and move our data there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21c18d-1833-4bba-95e6-fc27835f1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have 5 age ranges, this means we have 5 labels.\n",
    "\n",
    "# Creating relevant directory\n",
    "train_dir = \"datasets/labcrop_utkface/train\"\n",
    "val_dir = \"datasets/labcrop_utkface/val\"\n",
    "test_dir = \"datasets/labcrop_utkface/test\"\n",
    "dirlist = [train_dir, val_dir, test_dir]\n",
    "lablist = [\"/A0\", \"/A1\", \"/A2\", \"/A3\", \"/A4\"]\n",
    "\n",
    "for datadir in dirlist:\n",
    "    directory = datadir+lablist    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e528700-1d23-4dd4-a25a-a0a5be1518c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"datasets/cropped_utkface\"\n",
    "allimages = os.listdir(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292afb6-897a-4f5d-881e-ee4545684927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_data(data, train_percent=0.8, validation_percent=0.1, test_percent=0.1):\n",
    "    total_size = len(data)\n",
    "    train_size = int(total_size * train_percent)\n",
    "    validation_size = int(total_size * validation_percent)\n",
    "    \n",
    "    # Ensure that the sizes add up to the total size\n",
    "    test_size = total_size - train_size - validation_size\n",
    "    \n",
    "    # Shuffle the data randomly\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    # Split the data into three sets\n",
    "    train_data = data[:train_size]\n",
    "    validation_data = data[train_size:train_size + validation_size]\n",
    "    test_data = data[train_size + validation_size:]\n",
    "    \n",
    "    return train_data, validation_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e158ef-0992-4695-b27d-1ad0863dabf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def copy_file(source_path, destination_path):\n",
    "    try:\n",
    "        shutil.copy(source_path, destination_path)\n",
    "        # print(f\"File copied successfully from {source_path} to {destination_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Source file not found: {source_path}\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission error. Make sure you have the necessary permissions.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd36dd-691c-4199-8824-1dd66214886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def assign_folders(savedir, dataset):\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-15.m116",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-15:m116"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
