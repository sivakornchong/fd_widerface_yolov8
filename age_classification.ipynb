{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e336bb8-f6d5-4b4d-9d32-e4ff21fe1b42",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Here, we will use RESNET34 architecture to train a classification model to identify the age range of images.\n",
    "\n",
    "Age range definition based on Health Promotion Board of Singapore\n",
    "- (A0) Young Children: 0-6 years \n",
    "- (A1) Children and Youth: 7-17 years \n",
    "- (A2) Youth Adults: 18-25 years\n",
    "- (A3) Adults: 26-49 years\n",
    "- (A4) Older adults: 50 years\n",
    "\n",
    "The training data used is from UTKFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d52c281-b025-43bd-84f0-208b2908e5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "save_directory = \"imgs/cropface/\"\n",
    "# img = cv2.imread(sample_img)\n",
    "classNames = [\"face\"]\n",
    "\n",
    "def cropimgs(results, save_directory, expand_ratio = 0.2, CI = 0.7):\n",
    "    # results: list of results for all the images after running the model\n",
    "    # save_directory: location of output directory\n",
    "    # expand_ratio: expand the size of x1,x2 by expand_ratio percent. \n",
    "    # CI: confidence interval of prediction. Only crop the image if the confidence is higher than this threshold\n",
    "    \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        imgpath = r.path\n",
    "        img = cv2.imread(imgpath)\n",
    "        \n",
    "        cropstr = imgpath.split(\"/\")[-1].split(\".jpg\")[0]\n",
    "        img_index = 0\n",
    "\n",
    "        for box in boxes:\n",
    "            # bounding box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "            \n",
    "            # Calculate expanded coordinates\n",
    "            x1 = max(0, int(x1 - expand_ratio * (x2 - x1)))\n",
    "            y1 = max(0, int(y1 - expand_ratio * (y2 - y1)))\n",
    "            x2 = min(img.shape[1], int(x2 + expand_ratio * (x2 - x1)))\n",
    "            y2 = min(img.shape[0], int(y2 + expand_ratio * (y2 - y1)))\n",
    "\n",
    "            # put box in cam\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # confidence\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            # print(\"Confidence --->\",confidence)\n",
    "\n",
    "            # # class name\n",
    "            # cls = int(box.cls[0])\n",
    "            # print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "            if classNames[cls] == \"face\" and confidence > CI:\n",
    "                # Crop the person from the image\n",
    "                cropped_person = img[y1:y2, x1:x2]\n",
    "\n",
    "                # Save the cropped person image\n",
    "                filename = f\"{save_directory}{cropstr}_{img_index}.jpg\"\n",
    "                cv2.imwrite(filename, cropped_person)\n",
    "                img_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efc1d4-4097-4e6f-a0ac-4a9764bb352e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-15.m116",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-15:m116"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
